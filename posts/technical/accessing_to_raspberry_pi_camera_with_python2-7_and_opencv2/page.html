<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml" dir="ltr">


<head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

<meta name="description" content="">
<meta name="keywords" content="">
<meta name="author" content="">
<link rel="stylesheet" type="text/css" href="/reset.css" media="screen">
<link rel="stylesheet" type="text/css" href="/style.css" media="screen">
<!--[if lte IE 7]><link rel="stylesheet" type="text/css" href="ie_fixes.css" media="screen" /><![endif]-->
<title>Dennis Núñez Fernández</title>

<!-- Favicon of the website -->
<link rel="shortcut icon" href="/icon.ico?" type="image/x-icon" />
<link rel="icon" href="/icon.ico?" type="image/ico" />

<style type="text/css">:root .adsbygoogle,
:root #header + #content > #left > #rlblock_left,
:root #content > #right > .dose > .dosesingle,
:root #content > #center > .dose > .dosesingle
{display:none !important;}</style>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-115924652-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-115924652-1');
</script>

</head>


<body>
<div id="paper_left">
<div id="paper_right">
<div id="layout_wrapper">
<div id="layout_container">
<div id="layout_content">
<div id="site_title">
<h1><b><a href="https://dennishnf.com/">Dennis Núñez Fernández</a></b></h1>
<h2>B.Sc. in Electronic Engineering, Universidad Nacional de Ingeniería (UNI)</h2>
</div>
<div class="navigation">
<ul>
<li><a href="/index.html">Home</a></li>
<li><a href="/research/research.html">Research</a></li>
<li><a href="/posts/posts.html">Posts</a></li>
<li><a href="/contact/contact.html">Contact</a></li>
<li><a href="/curriculum/curriculum.html">Curriculum</a></li>
</ul>
<div class="clearer">&nbsp;</div>
</div>

<div id="main">

<div class="post">
<div class="post_body">
<br/>

<h2>Accessing to Raspberry Pi camera with Python 2.7 and OpenCV 2</h2>

<p align="justify">Once installed Python 2.7 and Opencv 2, now we can finally start writing some code!.</p>
<br/> 
<h3>Connect to RPI with SSH and Xephyr</h3>

<p align="justify">First, on Ubuntu:</p>
<p><code class="barcode">$ Xephyr -ac -br -keybd ephyr,,,xkbmodel=pc105,xkblayout=es -noreset -screen 1280x720 :1
</code></p>

<p align="justify">Then, on RPI:</p>
<p><code class="barcode">$ DISPLAY=:1 ssh -Y pi@10.42.0.246
$ startlxde
</code></p>

<br/> 
<h3>Accessing a single image of your Raspberry Pi using Python and OpenCV</h3>

<p align="justify">Open up a new file, name it <custom_code>test_image.py</custom_code>, and insert the following code:</p>
<p><code class="barcode"># import the necessary packages
from picamera.array import PiRGBArray
from picamera import PiCamera
import time
import cv2
     
# initialize the camera and grab a reference to the raw camera capture
camera = PiCamera()
rawCapture = PiRGBArray(camera)
     
# allow the camera to warmup
time.sleep(0.1)
     
# grab an image from the camera
camera.capture(rawCapture, format="bgr")
image = rawCapture.array
     
# display the image on screen and wait for a keypress
cv2.imshow("Image", image)
cv2.waitKey(0)
</code></p>

<p align="justify">We’ll start by importing our necessary packages on Lines 2-5.</p>
<p align="justify">From there, we initialize our PiCamera object on Line 8 and grab a reference to the raw capture component on Line 9. This rawCapture  object is especially useful since it (1) gives us direct access to the camera stream and (2) avoids the expensive compression to JPEG format, which we would then have to take and decode to OpenCV format anyway. I highly recommend that you use PiRGBArray  whenever you need to access the Raspberry Pi camera — the performance gains are well worth it.</p>
<p align="justify">From there, we sleep for a tenth of a second on Line 12 — this allows the camera sensor to warm up.</p>
<p align="justify">Finally, we grab the actual photo from the rawCapture  object on Line 15 where we take special care to ensure our image is in BGR format rather than RGB. OpenCV represents images as NumPy arrays in BGR order rather than RGB — this little nuisance is subtle, but very important to remember as it can lead to some confusing bugs in your code down the line.</p>
<p align="justify">Finally, we display our image to screen on Lines 19 and 20.</p>
<p align="justify">To execute this example, open up a terminal, navigate to your test_image.py  file, and issue the following command:</p>
<p><code class="barcode">$ python test_image.py
</code></p>

<p align="justify">If all goes as expected you should have an image displayed on your screen.</p>
<br/> 
<h3>Accessing the video stream of your Raspberry Pi using Python and OpenCV</h3>

<p align="justify">Alright, so we’ve learned how to grab a single image from the Raspberry Pi camera. But what about a video stream?.</p>
<p align="justify">You might guess that we are going to use the cv2.VideoCapture  function here — but I actually recommend against this. Getting cv2.VideoCapture  to play nice with your Raspberry Pi is not a nice experience (you’ll need to install extra drivers) and something you should generally avoid.</p>
<p align="justify">And besides, why would we use the cv2.VideoCapture  function when we can easily access the raw video stream using the picamera  module?.</p>
<p align="justify">Let’s go ahead and take a look on how we can access the video stream. Open up a new file, name it <custom_code>test_video.py</custom_code>, and insert the following code:</p>
<p><code class="barcode"># import the necessary packages
from picamera.array import PiRGBArray
from picamera import PiCamera
import time
import cv2
     
# initialize the camera and grab a reference to the raw camera capture
camera = PiCamera()
camera.resolution = (640, 480)
camera.framerate = 32
rawCapture = PiRGBArray(camera, size=(640, 480))
     
# allow the camera to warmup
time.sleep(0.1)
     
# capture frames from the camera
for frame in camera.capture_continuous(rawCapture, format="bgr", use_video_port=True):
  # grab the raw NumPy array representing the image, then initialize the timestamp
  # and occupied/unoccupied text
  image = frame.array
     
  # show the frame
  cv2.imshow("Frame", image)
  key = cv2.waitKey(1) & 0xFF
     
  # clear the stream in preparation for the next frame
  rawCapture.truncate(0)
     
  # if the `q` key was pressed, break from the loop
  if key == ord("q"):
    break
</code></p>

<p align="justify">This example starts off similarly to the previous one. We start off by importing our necessary packages on Lines 2-5.</p>
<p align="justify">And from there we construct our camera  object on Line 8 which allows us to interface with the Raspberry Pi camera. However, we also take the time to set the resolution of our camera (640 x 480 pixels) on Line 9 and the frame rate (i.e. frames per second, or simply FPS) on Line 10. We also initialize our PiRGBArray  object on Line 11, but we also take care to specify the same resolution as on Line 9.</p>
<p align="justify">Accessing the actual video stream is handled on Line 17 by making a call to the capture_continuous  method of our camera  object.</p>
<p align="justify">This method returns a frame  from the video stream. The frame then has an array  property, which corresponds to the frame  in NumPy array format — all the hard work is done for us on Lines 17 and 20!.</p>
<p align="justify">We then take the frame of the video and display on screen on Lines 23 and 24.</p>
<p align="justify">An important line to pay attention to is Line 27: You must clear the current frame before you move on to the next one!.</p>
<p align="justify">If you fail to clear the frame, your Python script will throw an error — so be sure to pay close attention to this when implementing your own applications!.</p>
<p align="justify">Finally, if the user presses the q  key, we break form the loop and exit the program.</p>
<p align="justify">To execute our script, just open a terminal (making sure you are in the cv  virtual environment, of course) and issue the following command:</p>
<p><code class="barcode">$ python test_video.py
</code></p>

<p align="justify">If all goes as expected you should have a video stream displayed on your screen.</p>
<br/> 
<h3>Resources</h3>

<p align="justify">- <a target="_blank" href="https://www.pyimagesearch.com/2015/03/30/accessing-the-raspberry-pi-camera-with-opencv-and-python/">https://www.pyimagesearch.com/2015/03/30/accessing-the-raspberry-pi-camera-with-opencv-and-python/</a>.</p>

<br/>
</div>
</div>



</div>



<div id="footer">
<div class="left">© 2013–2020 Dennis H. Núñez Fernández <br/>  <!-- </div> 
<div class="clearer">&nbsp;</div>
</div>

</div>
</div>
</div>
</div>
</div>

</body></html> -->
<a href="https://dennishnf.com/README.html" target="_blank">From scratch by Python. Powered by Linux</a> <br/>
Website updated: 2021-03-07  23:16 GMT <br/> 
</div> 
<div class="clearer">&nbsp;</div> 
</div> 
</div> 
</div> 
</div> 
</div> 
</div> 
</body> 


</html> 
