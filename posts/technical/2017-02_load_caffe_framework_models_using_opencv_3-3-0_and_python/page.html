<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml" dir="ltr">


<head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

<meta name="description" content="">
<meta name="keywords" content="">
<meta name="author" content="">
<link rel="stylesheet" type="text/css" href="/reset.css" media="screen">
<link rel="stylesheet" type="text/css" href="/style.css" media="screen">
<!--[if lte IE 7]><link rel="stylesheet" type="text/css" href="ie_fixes.css" media="screen" /><![endif]-->
<title>Dennis Núñez Fernández</title>

<!-- Favicon of the website -->
<link rel="shortcut icon" href="/icon.ico?" type="image/x-icon" />
<link rel="icon" href="/icon.ico?" type="image/ico" />

<style type="text/css">:root .adsbygoogle,
:root #header + #content > #left > #rlblock_left,
:root #content > #right > .dose > .dosesingle,
:root #content > #center > .dose > .dosesingle
{display:none !important;}</style>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-115924652-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-115924652-1');
</script>

</head>


<body>
<div id="paper_left">
<div id="paper_right">
<div id="layout_wrapper">
<div id="layout_container">
<div id="layout_content">
<div id="site_title">
<h1><b><a href="https://dennishnf.com/">Dennis Núñez Fernández</a></b></h1>
<h2>BSc in Electronic Engineering, Universidad Nacional de Ingeniería (UNI)</h2>
</div>
<div class="navigation">
<ul>
<li><a href="/index.html">Home</a></li>
<li><a href="/research/research.html">Research</a></li>
<li><a href="/posts/posts.html">Posts</a></li>
<li><a href="/contact/contact.html">Contact</a></li>
<li><a href="/curriculum/curriculum.html">Curriculum</a></li>
</ul>
<div class="clearer">&nbsp;</div>
</div>

<div id="main">

<div class="post">
<div class="post_body">
<br/>

<h2>Load Caffe framework models using OpenCV 3.3.0 and Python</h2>

<br/> 
<h3>Load Caffe framework models using OpenCV</h3>

<p align="justify">In this tutorial you will learn how to use dnn module for image classification by using GoogLeNet and SqueezeNet trained networks from Caffe model zoo.</p>
<p align="justify">We will demonstrate results of this example on the following picture.</p>

<center><img src="https://dennishnf.github.io/posts/technical/2017-02_load_caffe_framework_models_using_opencv_3-3-0_and_python/image.png" style="padding-top:8px; padding-bottom: 8px;" /></center>


<br/> 
<h3>Source Code</h3>

<p align="justify">This code was tested on Python 2.7 and works fine. We will be using the next code, that can be downloaded here: [<a target="_blank" href="https://dennishnf.github.io/posts/technical/2017-02_load_caffe_framework_models_using_opencv_3-3-0_and_python/pi_deep_learning.zip">link</a>].</p>
<p><code class="barcode"># USAGE
# python pi_deep_learning.py --prototxt models/bvlc_googlenet.prototxt --model models/bvlc_googlenet.caffemodel --labels synset_words.txt --image images/barbershop.png
# python pi_deep_learning.py --prototxt models/squeezenet_v1.0.prototxt --model models/squeezenet_v1.0.caffemodel --labels synset_words.txt --image images/barbershop.png
     
# import the necessary packages
import numpy as np
import argparse
import time
import cv2
     
# construct the argument parse and parse the arguments
ap = argparse.ArgumentParser()
ap.add_argument("-i", "--image", required=True,
	help="path to input image")
ap.add_argument("-p", "--prototxt", required=True,
	help="path to Caffe 'deploy' prototxt file")
ap.add_argument("-m", "--model", required=True,
	help="path to Caffe pre-trained model")
ap.add_argument("-l", "--labels", required=True,
	help="path to ImageNet labels (i.e., syn-sets)")
args = vars(ap.parse_args())
     
# load the class labels from disk
rows = open(args["labels"]).read().strip().split("\n")
classes = [r[r.find(" ") + 1:].split(",")[0] for r in rows]
     
# load the input image from disk
image = cv2.imread(args["image"])
     
# our CNN requires fixed spatial dimensions for our input image(s)
# so we need to ensure it is resized to 224x224 pixels while
# performing mean subtraction (104, 117, 123) to normalize the input;
# after executing this command our "blob" now has the shape:
# (1, 3, 224, 224)
blob = cv2.dnn.blobFromImage(image, 1, (224, 224), (104, 117, 123))
     
# load our serialized model from disk
print("[INFO] loading model...")
net = cv2.dnn.readNetFromCaffe(args["prototxt"], args["model"])
     
# set the blob as input to the network and perform a forward-pass to
# obtain our output classification
net.setInput(blob)
start = time.time()
preds = net.forward()
end = time.time()
print("[INFO] classification took {:.5} seconds".format(end - start))
     
# sort the indexes of the probabilities in descending order (higher
# probabilitiy first) and grab the top-5 predictions
preds = preds.reshape((1, len(classes)))
idxs = np.argsort(preds[0])[::-1][:5]
     
# loop over the top-5 predictions and display them
for (i, idx) in enumerate(idxs):
	# draw the top prediction on the input image
	if i == 0:
		text = "Label: {}, {:.2f}%".format(classes[idx],
			preds[0][idx] * 100)
		cv2.putText(image, text, (5, 25), cv2.FONT_HERSHEY_SIMPLEX,
			0.7, (0, 0, 255), 2)
     
	# display the predicted label + associated probability to the
	# console	
	print("[INFO] {}. label: {}, probability: {:.5}".format(i + 1,
		classes[idx], preds[0][idx]))
     
# display the output image
cv2.imshow("Image", image)
cv2.waitKey(0)
</code></p>

<br/> 
<h3>Run GoogleNet</h3>

<p><code class="barcode">$ cd ~/Desktop/pi_deep_learning
$ python pi_deep_learning.py --prototxt models/bvlc_googlenet.prototxt --model models/bvlc_googlenet.caffemodel --labels synset_words.txt --image images/barbershop.png
</code></p>


<center><img src="https://dennishnf.github.io/posts/technical/2017-02_load_caffe_framework_models_using_opencv_3-3-0_and_python/result1.png" style="padding-top:8px; padding-bottom: 8px;" /></center>


<br/> 
<h3>Run SqueezeNet</h3>

<p><code class="barcode">$ cd ~/Desktop/pi_deep_learning
$ python pi_deep_learning.py --prototxt models/squeezenet_v1.0.prototxt --model models/squeezenet_v1.0.caffemodel --labels synset_words.txt --image images/barbershop.png
</code></p>


<center><img src="https://dennishnf.github.io/posts/technical/2017-02_load_caffe_framework_models_using_opencv_3-3-0_and_python/result2.png" style="padding-top:8px; padding-bottom: 8px;" /></center>


<br/> 
<h3>Resources</h3>

<p align="justify">- <a target="_blank" href="https://www.pyimagesearch.com/2017/10/02/deep-learning-on-the-raspberry-pi-with-opencv/">https://www.pyimagesearch.com/2017/10/02/deep-learning-on-the-raspberry-pi-with-opencv/</a>.</p>

<br/>
</div>
</div>



</div>



<div id="footer">
<div class="left">© 2013–2020 Dennis H. Núñez Fernández <br/>  <!-- </div> 
<div class="clearer">&nbsp;</div>
</div>

</div>
</div>
</div>
</div>
</div>

</body></html> -->
<a href="https://dennishnf.com/README.html" target="_blank">From scratch by Python. Powered by Linux</a> <br/>
Website updated: 2021-03-30  16:40 GMT <br/> 
</div> 
<div class="clearer">&nbsp;</div> 
</div> 
</div> 
</div> 
</div> 
</div> 
</div> 
</body> 


</html> 
